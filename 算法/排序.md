### 排序

#### 一.排序算法的执行效率
1. **最好情况、最坏情况、平均情况时间复杂度**
   为什么要区分这三种时间复杂度呢？第一，有些排序算法会区分，为了好对比，所以我们最好都做一下区分。第二，对于要排序的数据，有的接近有序，有的完全无序。有序度不同的数据，对于排序的执行时间肯定是有影响的，我们要知道排序算法在不同数据下的性能表现。
2. **时间复杂度的系数、常数 、低阶**
   我们知道，时间复杂度反映的是数据规模 n 很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低阶。但是实际的软件开发中，我们排序的可能是 10 个、100 个、1000 个这样规模很小的数据，所以，在对同一阶时间复杂度的排序算法性能对比的时候，我们就要把系数、常数、低阶也考虑进来。
3. **比较次数和交换（或移动）次数**
   基于比较的排序算法的执行过程，会涉及两种操作，一种是元素比较大小，另一种是元素交换或移动。所以，如果我们在分析排序算法的执行效率的时候，应该把比较次数和交换（或移动）次数也考虑进去。

#### 二.排序算法的内存消耗
**原地排序**（Sorted in place）。原地排序算法，就是特指空间复杂度是 O(1) 的排序算法。

#### 三.排序算法的稳定性
稳定性, 这个概念是说，如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。
比如说，我们现在要给电商交易系统中的“订单”排序。订单有两个属性，一个是下单时间，另一个是订单金额。如果我们现在有 10 万条订单数据，我们希望按照金额从小到大对订单数据排序。对于金额相同的订单，我们希望按照下单时间从早到晚有序。对于这样一个排序需求，我们怎么来做呢？
借助稳定排序算法，这个问题可以非常简洁地解决。解决思路是这样的：我们先按照下单时间给订单排序，注意是按照下单时间，不是金额。排序完成之后，我们用稳定排序算法，按照订单金额重新排序。两遍排序之后，我们得到的订单数据就是按照金额从小到大排序，金额相同的订单按照下单时间从早到晚排序的。
![R](https://static001.geekbang.org/resource/image/13/59/1381c1f3f7819ae61ab17455ed7f0b59.jpg)
**重点：在数据集重复数据较多的时候，为了获取稳定性，我们将要排序的元素从有序集的尾部到头部这样的顺序进行比较**

#### 四.排序算法
1. **冒泡排序（Bubble Sort）**
   * **是否原地排序：是**
   * **是否稳定：是**
   * **时间复杂度：O($n^2$)**
   * **空间复杂度：O(1)**
   冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。
   ![t](https://static001.geekbang.org/resource/image/92/09/9246f12cca22e5d872cbfce302ef4d09.jpg)
   **冒泡过程还可以优化,当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作,如下图。**
   ![t](https://static001.geekbang.org/resource/image/a9/e6/a9783a3b13c11a5e064c5306c261e8e6.jpg)
   ```c++
   void buuble_sort(int a[], int length)
   {
       if (length <= 1) return;

       for(int i=length-1; i>=0 ; i--)
       {
           bool flag = false; //标记
           for(int j=0; j<i; j++)
           {
               if(a[j] > a[j+1])
               {
                   int temp = a[j];
                   a[j] = a[j+1];
                   a[j+1] = temp;
                   flag = true;
               }
           }
           if(!flag)
           {
               break;
           }
       }
   }
   ```
   **冒泡排序的时间复杂度计算技巧：**
    通过 **“有序度”** 和 **“逆序度”** 这两个概念来进行分析。  

    **有序度**是数组中具有有序关系的元素对的个数。
    ![t](https://static001.geekbang.org/resource/image/a1/20/a1ef4cc1999d6bd0af08d8417ee55220.jpg)
    同理，对于一个倒序排列的数组，比如 6，5，4，3，2，1，有序度是 0；对于一个完全有序的数组，比如 1，2，3，4，5，6，有序度就是 **n\*(n-1)/2**，也就是 15。我们把这种完全有序的数组的有序度叫作**满有序度**。  

    **逆序度**的定义正好跟有序度相反（默认从小到大为有序）
    我们还可以得到一个公式：**逆序度 = 满有序度 - 有序度**。我们排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，就说明排序完成了。  
    
    对于包含 n 个数据的数组进行冒泡排序，平均交换次数是多少呢？最坏情况下，初始状态的有序度是 0，所以要进行 n*(n-1)/2 次交换。最好情况下，初始状态的有序度是 n*(n-1)/2，就不需要进行交换。我们可以取个中间值 n*(n-1)/4，来表示初始有序度既不是很高也不是很低的平均情况。换句话说，平均情况下，需要 n*(n-1)/4 次交换操作，比较操作肯定要比交换操作多，而复杂度的上限是 O(n2)，所以平均情况下的时间复杂度就是 O(n2)。  
      

2. **插入排序（Insertion Sort）**
   * **是否原地排序：是**
   * **是否稳定：是**
   * **时间复杂度：O($n^2$)**
   * **空间复杂度：O(1)**
  我们将数组中的数据分为两个区间，**已排序区间**和**未排序区间**。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。如图所示，要排序的数据是 4，5，6，1，3，2，其中左侧为已排序区间，右侧是未排序区间。
  ![t](https://static001.geekbang.org/resource/image/b6/e1/b60f61ec487358ac037bf2b6974d2de1.jpg)
  插入排序也包含两种操作，一种是元素的比较，一种是元素的移动。当我们需要将一个数据 a 插入到已排序区间时，需要拿 a 与已排序区间的元素依次比较大小，找到合适的插入位置。找到插入点之后，我们还需要将插入点之后的元素顺序往后移动一位，这样才能腾出位置给元素 a 插入。  
    
  ```c++
  void insertion_sort(int a[], int length)
  {
      if (length <= 1) return;

      for(int i=1; i<length; i++)//初始化已排序空间只有一个元素，所以下标从1开始
      {
          int value = a[i];//空出a[i]位置，a[i]的值来自未排序区间
          int j=i-1;
          for(; j>=0; --j)
          {
              if(a[j] > value)
              {
                  a[j+1] = a[j];//因为之前在未排序空间空出了位置，往后搬移数据，空出当前a[j+1]位置
              }
              else
              {
                  break;
              }
          }
          a[j+1] = value;//将value放置空出来的a[j+1]位置
      }
  }
  ```
    
**为什么插入排序要比冒泡排序更受欢迎呢？**
我们前面分析冒泡排序和插入排序的时候讲到，冒泡排序不管怎么优化，元素交换的次数是一个固定值，是原始数据的逆序度。插入排序是同样的，不管怎么优化，元素移动的次数也等于原始数据的逆序度。但是，从代码实现上来看，冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序需要 3 个赋值操作，而插入排序只需要 1 个。我们来看这段操作：
```c++

//冒泡排序中数据的交换操作：
if (a[j] > a[j+1]) { // 交换
int tmp = a[j];
a[j] = a[j+1];
a[j+1] = tmp;
flag = true;
}

//插入排序中数据的移动操作：
if (a[j] > value) {
a[j+1] = a[j];  // 数据移动
} else {
break;
}
```
我们把执行一个赋值语句的时间粗略地计为单位时间（unit_time），然后分别用冒泡排序和插入排序对同一个逆序度是 K 的数组进行排序。用冒泡排序，需要 K 次交换操作，每次需要 3 个赋值语句，所以交换操作总耗时就是 3*K 单位时间。而插入排序中数据移动操作只需要 K 个单位时间。  

这个只是我们非常理论的分析，为了实验，针对上面的冒泡排序和插入排序的 Java 代码，我写了一个性能对比测试程序，随机生成 10000 个数组，每个数组中包含 200 个数据，然后在我的机器上分别用冒泡和插入排序算法来排序，冒泡排序算法大约 700ms 才能执行完成，而插入排序只需要 100ms 左右就能搞定！  
    
所以，虽然冒泡排序和插入排序在时间复杂度上是一样的，都是 O(n2)，但是如果我们希望把性能优化做到极致，那肯定首选插入排序。
  
  
3. **希尔（Shell Sort）**
   * **是否原地排序：是**
   * **是否稳定：否（单插入排序稳定，不同组同时插入排序有可能使相同元素打乱原有顺序）**
   * **时间复杂度：O($n^{3\over 2}$)**
   * **空间复杂度：O(1)**
  希尔排序是希尔（Donald Shell）于1959年提出的一种排序算法。希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破O(n2）的第一批算法之一。  
  希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。  
  我们来看下希尔排序的基本步骤，在此我们选择增量gap=length/2，缩小增量继续以gap = gap/2的方式，这种增量选择我们可以用一个序列来表示，{n/2,(n/2)/2...1}，称为增量序列。希尔排序的增量序列的选择与证明是个数学难题，我们选择的这个增量序列是比较常用的，也是希尔建议的增量，称为希尔增量，但其实这个增量序列不是最优的。此处我们做示例使用希尔增量。  
  ![t](https://images2015.cnblogs.com/blog/1024555/201611/1024555-20161128110416068-1421707828.png)
  ```c++
  void shell_sort(int a[], int length)
  {
      if (length <= 1) return;

      for(int gap = length/2; gap>0; gap /= 2)
      {
          for(int i=gap; i<length; i += gap)//插入排序
          {
              int value = a[i];
              int j = i-gap;
              for(; j>=0; j-=gap)
              {
                  if(a[j]>value)
                  {
                      a[j+gap] = a[j];
                  }
                  else
                  {
                      break;
                  }
              }
              a[j+gap] = value;
          }
      }
  }
  ```
  **希尔排序没有快速排序算法快 O(n(logn))，因此中等大小规模表现良好，对规模非常大的数据排序不是最优选择。但是比O($n^2$)复杂度的算法快得多。并且希尔排序非常容易实现，算法代码短而简单。 此外，希尔算法在最坏的情况下和平均情况下执行效率相差不是很多，与此同时快速排序在最坏的情况下执行的效率会非常差。专家们提倡，几乎任何排序工作在开始时都可以用希尔排序，若在实际使用中证明它不够快，再改成快速排序这样更高级的排序算法.**

4. **选择排序（Selection Sort）**
   * **是否原地排序：是**
   * **是否稳定：否**
   * **时间复杂度：O($n^2$)**
   * **空间复杂度：O(1)**
  ![t](https://static001.geekbang.org/resource/image/32/1d/32371475a0b08f0db9861d102474181d.jpg)
  ```c++
  void selection_sort(int a[], int length)
  {
      if(length <= 1) return;
      for(int i=0; i<length-1; i++)
      {
          int index = i;
          for(int j=i; j<length; j++)
          {
              if(a[j]<a[index])
              {
                  index = j;
              }
          }
          int temp = a[i];
          a[i] = a[index];
          a[index] = temp;
      }
  }
  ```

5. **归并排序（Merge Sort）**
   * **是否原地排序：否**
   * **是否稳定：是**
   * **时间复杂度：O(nlogn) (最好最坏都是O(nlogn))**
   * **空间复杂度：O(n)**
  归并排序的核心思想还是蛮简单的。如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。
  ![t](https://static001.geekbang.org/resource/image/db/2b/db7f892d3355ef74da9cd64aa926dc2b.jpg)
  归并排序使用的就是分治思想。分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。  
  伪代码
  ```c++
    // 归并排序算法, A是数组，n表示数组大小
    merge_sort(A, n) {
    merge_sort_c(A, 0, n-1)
    }

    // 递归调用函数
    merge_sort_c(A, p, r) {
    // 递归终止条件
    if p >= r  then return

    // 取p到r之间的中间位置q
    q = (p+r) / 2
    // 分治递归
    merge_sort_c(A, p, q)
    merge_sort_c(A, q+1, r)
    // 将A[p...q]和A[q+1...r]合并为A[p...r]
    merge(A[p...r], A[p...q], A[q+1...r])
    }
  ```
  你可能已经发现了，merge(A[p...r], A[p...q], A[q+1...r]) 这个函数的作用就是，将已经有序的 A[p...q]和 A[q+1....r]合并成一个有序的数组，并且放入 A[p....r]。那这个过程具体该如何做呢？  
  如图所示，我们申请一个临时数组 tmp，大小与 A[p...r]相同。我们用两个游标 i 和 j，分别指向 A[p...q]和 A[q+1...r]的第一个元素。比较这两个元素 A[i]和 A[j]，如果 A[i]<=A[j]，我们就把 A[i]放入到临时数组 tmp，并且 i 后移一位，否则将 A[j]放入到数组 tmp，j 后移一位。  
  继续上述比较过程，直到其中一个子数组中的所有数据都放入临时数组中，再把另一个数组中的数据依次加入到临时数组的末尾，这个时候，临时数组中存储的就是两个子数组合并之后的结果了。最后再把临时数组 tmp 中的数据拷贝到原数组 A[p...r]中。  
  ![t](https://static001.geekbang.org/resource/image/95/2f/95897ade4f7ad5d10af057b1d144a22f.jpg)
  
  
  完整代码：
  ```c++
  void merge(int a[], int left, int middle, int right)
  {
      int* temp = new int[right-left+1];
      int i=left;
      int j=middle+1;
      int k = 0;
      while (i<=middle && j<=right) {
          if(a[i]<=a[j]){//<= 保持算法稳定的关键
              temp[k++] = a[i++];
              if(i>middle && j<=right)
              {
                  while(j<=right)
                  {
                      temp[k++] = a[j++];
                  }
                  break;
              }
          }
          else
          {
              temp[k++] = a[j++];
              if(i<=middle && j>right)
              {
                  while(i<=middle)
                  {
                      temp[k++] = a[i++];
                  }
                  break;
              }
          }
      }
      
      int size = right-left;
      for(int index=0; index<=size; index++)
      {
          a[left+index] = temp[index];
      }
      
      delete []temp;
  }

  void merge_sort_c(int a[], int left, int right)
  {
      if (left>=right) return;

      int middle = left + (right - left)/2;

      merge_sort_c(a, left, middle);
      merge_sort_c(a, middle+1, right);
      merge(a, left, middle, right);
  }

  void merge_sort(int a[], int length)
  {
      merge_sort_c(a, 0, length-1);
  }
  ```  
    
**归并排序的时间复杂度计算：**
归并排序涉及递归，时间复杂度的分析稍微有点复杂。我们正好借此机会来学习一下，如何分析递归代码的时间复杂度。  
  
在递归那一节我们讲过，递归的适用场景是，一个问题 a 可以分解为多个子问题 b、c，那求解问题 a 就可以分解为求解问题 b、c。问题 b、c 解决之后，我们再把 b、c 的结果合并成 a 的结果。  

如果我们定义求解问题 a 的时间是 T(a)，求解问题 b、c 的时间分别是 T(b) 和 T( c)，那我们就可以得到这样的递推关系式：
```
T(a) = T(b) + T(c) + K
```  
其中 K 等于将两个子问题 b、c 的结果合并成问题 a 的结果所消耗的时间。  
  
从刚刚的分析，我们可以得到一个重要的结论：不仅递归求解的问题可以写成递推公式，递归代码的时间复杂度也可以写成递推公式。  
  
套用这个公式，我们来分析一下归并排序的时间复杂度。  
  
我们假设对 n 个元素进行归并排序需要的时间是 T(n)，那分解成两个子数组排序的时间都是 T(n/2)。我们知道，merge() 函数合并两个有序子数组的时间复杂度是 O(n)。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是：  
```
T(1) = C；   n=1时，只需要常量级的执行时间，所以表示为C。
T(n) = 2*T(n/2) + n； n>1
```  
  
通过这个公式，如何来求解 T(n) 呢？还不够直观？那我们再进一步分解一下计算过程。  
  
```
T(n) = 2*T(n/2) + n
     = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n
     = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n
     = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n
     ......
     = 2^k * T(n/2^k) + k * n
     ......
```  
  
通过这样一步一步分解推导，我们可以得到 T(n) = $2^kT$(n/$2^k$)+kn。当 T(n/$2^k$)=T(1) 时，也就是 n/$2^k$=1，我们得到 k=log2n 。我们将 k 值代入上面的公式，得到 T(n)=Cn+nlog2n 。如果我们用大 O 标记法来表示的话，T(n) 就等于 O(nlogn)。所以归并排序的时间复杂度是 O(nlogn)。  
  
从我们的原理分析和伪代码可以看出，归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)。
  
    
**归并排序的空间复杂度计算:**
归并排序的时间复杂度任何情况下都是 O(nlogn)，看起来非常优秀。（待会儿你会发现，即便是快速排序，最坏情况下，时间复杂度也是 O(n2)。）但是，归并排序并没有像快排那样，应用广泛，这是为什么呢？因为它有一个致命的“弱点”，那就是归并排序不是原地排序算法。  
  
这是因为归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。这一点你应该很容易理解。那我现在问你，归并排序的空间复杂度到底是多少呢？是 O(n)，还是 O(nlogn)，应该如何分析呢？  
  
如果我们继续按照分析递归时间复杂度的方法，通过递推公式来求解，那整个归并过程需要的空间复杂度就是 O(nlogn)。不过，类似分析时间复杂度那样来分析空间复杂度，这个思路对吗？  
  
实际上，递归代码的空间复杂度并不能像时间复杂度那样累加。刚刚我们忘记了最重要的一点，那就是，尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)。  
  
    
6. **快速排序（Quick Sort）**
   * **是否原地排序：是**
   * **是否稳定：否**
   * **时间复杂度：O(nlogn) (最坏都是O($n^2$))**
   * **空间复杂度：O(nlogn)**
快排的思想是这样的：如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。  
我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。  
![T](https://static001.geekbang.org/resource/image/4d/81/4d892c3a2e08a17f16097d07ea088a81.jpg)
```
递推公式：
quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1… r)

终止条件：
p >= r
```
如果我们不考虑空间消耗的话，partition() 分区函数可以写得非常简单。我们申请两个临时数组 X 和 Y，遍历 A[p...r]，将小于 pivot 的元素都拷贝到临时数组 X，将大于 pivot 的元素都拷贝到临时数组 Y，最后再将数组 X 和数组 Y 中数据顺序拷贝到 A[p....r]。  
![t](https://static001.geekbang.org/resource/image/66/dc/6643bc3cef766f5b3e4526c332c60adc.jpg)
但是，如果按照这种思路实现的话，partition() 函数就需要很多额外的内存空间，所以快排就不是原地排序算法了。如果我们希望快排是原地排序算法，那它的空间复杂度得是 O(1)，那 partition() 分区函数就不能占用太多额外的内存空间，我们就需要在 A[p...r]的原地完成分区操作。原地分区函数的实现思路非常巧妙，我写成了伪代码，我们一起来看一下。  
```
partition(A, p, r) {
  pivot := A[r]
  i := p
  for j := p to r-1 do {
    if A[j] < pivot {
      swap A[i] with A[j]
      i := i+1
    }
  }
  swap A[i] with A[r]
  return i

```
  
这里的处理有点类似选择排序。我们通过游标 i 把 A[p...r-1]分成两部分。A[p...i-1]的元素都是小于 pivot 的，我们暂且叫它“已处理区间”，A[i...r-1]是“未处理区间”。我们每次都从未处理的区间 A[i...r-1]中取一个元素 A[j]，与 pivot 对比，如果小于 pivot，则将其加入到已处理区间的尾部，也就是 A[i]的位置。  
  
数组的插入操作还记得吗？在数组某个位置插入元素，需要搬移数据，非常耗时。当时我们也讲了一种处理技巧，就是交换，在 O(1) 的时间复杂度内完成插入操作。这里我们也借助这个思想，只需要将 A[i]与 A[j]交换，就可以在 O(1) 时间复杂度内将 A[j]放到下标为 i 的位置。  
  
文字不如图直观，所以我画了一张图来展示分区的整个过程。  
![t](https://static001.geekbang.org/resource/image/08/e7/086002d67995e4769473b3f50dd96de7.jpg)
因为分区的过程涉及交换操作，如果数组中有两个相同的元素，比如序列 6，8，7，6，3，5，9，4，在经过第一次分区操作之后，两个 6 的相对先后顺序就会改变。所以，**快速排序并不是一个稳定的排序算法**。
完整代码：
```c++
int sort(int a[], int left, int right, int pivot)
{
    //类似选择排序，原地排序，空间复杂度O(1)
    int i = left;
    for(int j=i; j<=right; j++)
    {
        if(a[j]<a[pivot])
        {
            int temp = a[i];
            a[i] = a[j];
            a[j] = temp;
            ++i;
        }
    }
    int temp = a[i];
    a[i] = a[pivot];
    a[pivot] = temp;
    return i;
}

void quick_sort_c(int a[], int left, int right, int pivot)
{
    if(left >= right) return;
    int p = sort(a, left, right, pivot);
    quick_sort_c(a, left, p-1, p-1);
    quick_sort_c(a, p+1, right, right);
}

void quick_sort(int a[], int length)
{
    if(length <= 1) return;
    int pivot = length - 1;
    quick_sort_c(a, 0, length-1, pivot);
}
```  
  
到此，快速排序的原理你应该也掌握了。现在，我再来看另外一个问题：快排和归并用的都是分治思想，递推公式和递归代码也非常相似，那它们的区别在哪里呢？  
![t](https://static001.geekbang.org/resource/image/aa/05/aa03ae570dace416127c9ccf9db8ac05.jpg)
可以发现，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法。我们前面讲过，归并之所以是非原地排序算法，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。
